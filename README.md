# llmakits

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„Pythonå·¥å…·åŒ…ï¼Œç”¨äºç®€åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)çš„é›†æˆå’Œç®¡ç†ã€‚æ”¯æŒå¤šæ¨¡å‹è°ƒåº¦ã€æ•…éšœè½¬ç§»ã€è´Ÿè½½å‡è¡¡ç­‰åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒOpenAIã€æ™ºè°±AIã€DashScopeã€ModelScopeç­‰å¤šä¸ªä¸»æµLLMå¹³å°
- ğŸ”„ **æ™ºèƒ½è°ƒåº¦**: å†…ç½®æ¨¡å‹æ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡æœºåˆ¶
- ğŸ”‘ **å¯†é’¥ç®¡ç†**: çµæ´»çš„APIå¯†é’¥é…ç½®å’Œç®¡ç†
- ğŸ“Š **æ¶ˆæ¯å¤„ç†**: å¼ºå¤§çš„æ¶ˆæ¯æ ¼å¼åŒ–ã€éªŒè¯å’Œæå–åŠŸèƒ½
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**: å®Œå–„çš„é‡è¯•æœºåˆ¶å’Œå¼‚å¸¸å¤„ç†
- ğŸ“ **æµå¼è¾“å‡º**: æ”¯æŒæµå¼å“åº”å¤„ç†
- ğŸ¯ **ç”µå•†å·¥å…·**: å†…ç½®ç”µå•†åœºæ™¯ä¸“ç”¨å·¥å…·é›†

## å®‰è£…

```bash
pip install llmakits
```

æ›´æ–°ï¼š

```bash
pip install --upgrade llmakits
```

## å¿«é€Ÿå¼€å§‹

### 1. é…ç½®æ¨¡å‹å’ŒAPIå¯†é’¥

åˆ›å»ºé…ç½®æ–‡ä»¶ `config/models_config.yaml`ï¼š

```yaml
Models_config:
  my_models:
    - sdk_name: "openai"
      model_name: "gpt-3.5-turbo"
    - sdk_name: "zhipu"
      model_name: "glm-4-flash"
```

åˆ›å»ºé…ç½®æ–‡ä»¶ `config/keys_config.yaml`ï¼š

```yaml
openai:
  base_url: "https://api.openai.com/v1"
  api_keys:
    - "your-openai-api-key-1"
    - "your-openai-api-key-2"

zhipu:
  base_url: "https://open.bigmodel.cn/api/paas/v4"
  api_keys:
    - "your-zhipu-api-key"
```

### 2. åŠ è½½æ¨¡å‹

```python
from llmakits import load_models

# åŠ è½½é…ç½®å¥½çš„æ¨¡å‹
models = load_models('config/models_config.yaml', 'config/keys_config.yaml')

# è·å–æ¨¡å‹ç»„
my_models = models['my_models']
```

### 3. å‘é€æ¶ˆæ¯ï¼ˆå¤šæ¨¡å‹è°ƒåº¦ï¼‰

#### ä½¿ç”¨æ–°çš„ ModelDispatcher ç±»ï¼ˆæ¨èï¼‰

```python
from llmakits.dispatcher import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
dispatcher = ModelDispatcher()

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# æ‰§è¡Œä»»åŠ¡
result, tokens = dispatcher.execute_task(message_info, my_models)
print(f"ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")

# è·å–æ¨¡å‹åˆ‡æ¢æ¬¡æ•°
switch_count = dispatcher.model_switch_count
print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {switch_count}")

```

#### ä½¿ç”¨å…¼å®¹å‡½æ•°ï¼ˆæ—§ç‰ˆæœ¬ï¼‰

```python
from llmakits.dispatcher import execute_task

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# æ‰§è¡Œä»»åŠ¡
result, tokens, switch_count = execute_task(message_info, my_models)
print(f"ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")
print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {switch_count}")
```

### 4. ç›´æ¥ä½¿ç”¨æ¨¡å‹å®¢æˆ·ç«¯

```python
from llmakits import BaseOpenai

# åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
model = BaseOpenai(
    platform="openai",
    base_url="https://api.openai.com/v1",
    api_keys=["your-api-key"],
    model_name="gpt-3.5-turbo"
)

# å‘é€æ¶ˆæ¯
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹"},
    {"role": "user", "content": "Hello!"}
]

result, tokens = model.send_message(messages)
print(f"å›å¤: {result}")
```

## é«˜çº§åŠŸèƒ½

### æ¶ˆæ¯å¤„ç†

```python
from llmakits.message import prepare_messages, extract_field, convert_to_json

# å‡†å¤‡æ¶ˆæ¯
messages = prepare_messages(system="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹", user="è¯·å¸®å¿™", assistant="å¥½çš„")

# æå–å¹¶è½¬æ¢ä¸ºJSON
json_str = '{"name": "test"} some text'
result = convert_to_json(json_str)

# æå–å­—æ®µ
field_value = extract_field(json_str, "name")
print(field_value)  # è¾“å‡º: test

# æå–å¤šä¸ªå­—æ®µ
name, age = extract_field(json_str, "name", "age")
print(name)  # è¾“å‡º: test
print(age)  # è¾“å‡º: None

```

### ç”µå•†å·¥å…·

#### åŸºç¡€å·¥å…·å‡½æ•°

```python
from llmakits.e_commerce import contains_chinese, remove_chinese, shorten_title, validate_html

# ä½¿ç”¨ç®€å•å‡½æ•°
result = contains_chinese("æ™ºèƒ½æ‰‹æœº")  # è¿”å› True
title = shorten_title("ä¸€ä¸ªå¾ˆé•¿çš„å•†å“æ ‡é¢˜", 50)  # ç¼©å‡åˆ°50å­—ç¬¦

# HTMLéªŒè¯
allowed_tags = {'div', 'p', 'span', 'strong', 'em'}
is_valid, error_msg = validate_html("<div>å†…å®¹</div>", allowed_tags)
```

#### é«˜çº§ç”µå•†åŠŸèƒ½

```python
from llmakits.dispatcher import ModelDispatcher
from llmakits.e_commerce.kit import generate_title, predict_category, translate_options, validate_html_fix

# åˆ›å»ºè°ƒåº¦å™¨
dispatcher = ModelDispatcher()

# ç”Ÿæˆä¼˜åŒ–å•†å“æ ‡é¢˜
system_prompt = "ä½ æ˜¯ä¸€ä¸ªç”µå•†æ ‡é¢˜ä¼˜åŒ–ä¸“å®¶"
title = generate_title(
    dispatcher=dispatcher,
    title="åŸå§‹å•†å“æ ‡é¢˜",
    llm_models=my_models,
    system_prompt=system_prompt,
    max_length=225,
    min_length=10
)

# é¢„æµ‹å•†å“ç±»ç›®
cat_tree = {}  # ç±»ç›®æ ‘æ•°æ®
categories = predict_category(
    dispatcher=dispatcher,
    title="å•†å“æ ‡é¢˜",
    cat_tree=cat_tree,
    system_prompt="é¢„æµ‹å•†å“ç±»ç›®",
    llm_models=my_models
)

# ç¿»è¯‘å•†å“é€‰é¡¹
options = ["çº¢è‰²", "è“è‰²", "ç»¿è‰²"]
translated = translate_options(
    dispatcher=dispatcher,
    title="å•†å“æ ‡é¢˜",
    options=options,
    to_lang="english",
    llm_models=my_models,
    system_prompt="ç¿»è¯‘å•†å“é€‰é¡¹"
)

# éªŒè¯å¹¶ä¿®å¤HTML
html_content = "<div>å†…å®¹</div><script>alert('test')</script>"
allowed_tags = {'div', 'p', 'span'}
fixed_html = validate_html_fix(
    dispatcher=dispatcher,
    html_string=html_content,
    allowed_tags=allowed_tags,
    llm_models=my_models,
    prompt="ä¿®å¤HTMLä¸­çš„ä¸å…è®¸æ ‡ç­¾"
)
```

## é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½® (`models_config.yaml`)

æŒ‰åŠŸèƒ½åˆ†ç»„é…ç½®æ¨¡å‹ï¼Œæ”¯æŒä¸ºä¸åŒåœºæ™¯é…ç½®ä¸åŒçš„æ¨¡å‹ç»„åˆï¼š

```yaml
Models_config:
  # æ ‡é¢˜ç”Ÿæˆä¸“ç”¨æ¨¡å‹ç»„
  generate_title:
    - sdk_name: "dashscope"
      model_name: "qwen3-max-preview"

  # ç¿»è¯‘ä¸“ç”¨æ¨¡å‹ç»„
  translate_box:
    - sdk_name: "modelscope"
      model_name: "Qwen/Qwen3-32B"
```

### å¯†é’¥é…ç½® (`keys_config.yaml`)

æ”¯æŒå¤šå¯†é’¥é…ç½®ï¼Œè‡ªåŠ¨åˆ‡æ¢å’Œè´Ÿè½½å‡è¡¡ï¼š

```yaml
platform_name:
  base_url: "api-endpoint-url"
  api_keys:
    - "api-key-1"
    - "api-key-2"
```

## é”™è¯¯å¤„ç†

llmakitså†…ç½®äº†å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

- **è‡ªåŠ¨é‡è¯•**: è¯·æ±‚å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼Œæœ€å¤š5æ¬¡
- **å¯†é’¥åˆ‡æ¢**: APIå¯†é’¥å¤±æ•ˆæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨å¯†é’¥
- **æ¨¡å‹åˆ‡æ¢**: å½“å‰æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨å°è¯•ä¸‹ä¸€ä¸ªå¯ç”¨æ¨¡å‹
- **å¼‚å¸¸æ•è·**: è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯å’Œå¤„ç†å»ºè®®

## è®¸å¯è¯

Apache 2.0 License
