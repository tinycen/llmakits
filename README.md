# llmakits

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„Pythonå·¥å…·åŒ…ï¼Œç”¨äºç®€åŒ–å¤§è¯­è¨€æ¨¡å‹(LLM)çš„é›†æˆå’Œç®¡ç†ã€‚æ”¯æŒå¤šæ¨¡å‹è°ƒåº¦ã€æ•…éšœè½¬ç§»ã€è´Ÿè½½å‡è¡¡ç­‰åŠŸèƒ½ã€‚

[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/tinycen/llmakits)

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒOpenAIã€æ™ºè°±AIã€DashScopeã€ModelScopeç­‰å¤šä¸ªä¸»æµLLMå¹³å°ï¼›
- ğŸ”„ **æ™ºèƒ½è°ƒåº¦**: å†…ç½®æ¨¡å‹æ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡æœºåˆ¶ï¼›
  - è‡ªåŠ¨åˆ‡æ¢ï¼šå½“æ¨¡å‹å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸ªå¯ç”¨æ¨¡å‹ï¼›
  - è´Ÿè½½å‡è¡¡ï¼šToken æˆ– è¯·æ±‚æ¬¡æ•° è¾¾åˆ°ä¸Šé™åï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸ªapi_keyï¼›
  - APIå¯†é’¥ç”¨å°½å¤„ç†ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ç§»é™¤APIå¯†é’¥ç”¨å°½çš„æ¨¡å‹ï¼›
- ğŸ“Š **æ¶ˆæ¯å¤„ç†**: å¼ºå¤§çš„æ¶ˆæ¯æ ¼å¼åŒ–ã€éªŒè¯å’Œæå–åŠŸèƒ½ï¼›
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**: å®Œå–„çš„é‡è¯•æœºåˆ¶å’Œå¼‚å¸¸å¤„ç†ï¼›
- ğŸ“ **æµå¼è¾“å‡º**: æ”¯æŒæµå¼å“åº”å¤„ç†ï¼›
- â±ï¸ **æ€§èƒ½ç›‘æ§**: æ”¯æŒè®¾ç½®è€—æ—¶è­¦å‘Šé˜ˆå€¼ï¼Œç›‘æ§æ¨¡å‹å“åº”æ€§èƒ½ï¼›
- ğŸ¯ **ç”µå•†å·¥å…·**: å†…ç½®ç”µå•†åœºæ™¯ä¸“ç”¨å·¥å…·é›†ï¼›
- ğŸ’¡ **çŠ¶æ€ä¿æŒ**: æ¨¡å‹å®ä¾‹ç¼“å­˜ï¼Œé¿å…é‡å¤å®ä¾‹åŒ–ï¼Œä¿æŒAPIå¯†é’¥åˆ‡æ¢çŠ¶æ€ã€‚

## å®‰è£…/æ›´æ–°

```bash
pip install --upgrade llmakits
```

## å¿«é€Ÿå¼€å§‹

### 1. é…ç½®æ¨¡å‹å’ŒAPIå¯†é’¥

**æ¨¡å‹é…ç½®æ–‡ä»¶** (`config/models_config.yaml`):
- æ”¯æŒæŒ‰ä¸šåŠ¡åœºæ™¯åˆ†ç»„é…ç½®
- æ¯ä¸ªç»„å¯ä»¥é…ç½®å¤šä¸ªæ¨¡å‹ï¼Œå®ç°æ•…éšœè½¬ç§»
- æ¨¡å‹ä¼šæŒ‰é…ç½®é¡ºåºä¾æ¬¡å°è¯•ï¼Œç›´åˆ°æˆåŠŸ

```yaml
# æ ‡é¢˜ç”Ÿæˆä¸“ç”¨æ¨¡å‹ç»„
generate_title:
  - sdk_name: "dashscope"
    model_name: "qwen3-max-preview"

  - sdk_name: "zhipu"
    model_name: "glm-4-plus"

# ç¿»è¯‘ä¸“ç”¨æ¨¡å‹ç»„
translate_box:
  - sdk_name: "modelscope"
    model_name: "Qwen/Qwen3-32B"

  - sdk_name: "modelscope"
    model_name: "deepseek-ai/DeepSeek-V3"
```

**å¯†é’¥é…ç½®æ–‡ä»¶** (`config/keys_config.yaml`):
- æ”¯æŒå¤šå¯†é’¥é…ç½®ï¼Œè‡ªåŠ¨è´Ÿè½½å‡è¡¡
- å½“å¯†é’¥è¾¾åˆ°æ¯æ—¥ä½¿ç”¨é™åˆ¶æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥
- æ”¯æŒä¸åŒå¹³å°çš„ç‹¬ç«‹é…ç½®

```yaml
# é˜¿é‡Œäº‘DashScopeå¹³å°
dashscope:
  base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
  api_keys: ["your-api-key-1", "your-api-key-2"]

# ModelScopeå¹³å°
modelscope:
  base_url: "https://api-inference.modelscope.cn/v1/"
  api_keys: ["your-api-key-1", "your-api-key-2"]

```

#### é”™è¯¯å¤„ç†å’Œæ•…éšœè½¬ç§»

1. **æ¨¡å‹çº§åˆ«æ•…éšœè½¬ç§»**: å½“å‰æ¨¡å‹å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°åŒç»„çš„ä¸‹ä¸€ä¸ªæ¨¡å‹
2. **APIå¯†é’¥ç”¨å°½æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹ `API_KEY_EXHAUSTED` å¼‚å¸¸ï¼Œå¹¶ç§»é™¤å¯¹åº”çš„æ¨¡å‹
3. **ç»“æœéªŒè¯**: æ”¯æŒè‡ªå®šä¹‰éªŒè¯å‡½æ•°ï¼ŒéªŒè¯å¤±è´¥æ—¶è‡ªåŠ¨å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
4. **çŠ¶æ€ä¿æŒ**: æ¨¡å‹å®ä¾‹åœ¨dispatcherä¸­ç¼“å­˜ï¼Œä¿æŒAPIå¯†é’¥åˆ‡æ¢çŠ¶æ€

#### é…ç½®ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨æ¨¡å‹ç»„**: æ¨èä½¿ç”¨ `execute_with_group` æ–¹æ³•ï¼Œé¿å…é‡å¤å®ä¾‹åŒ–
2. **åˆç†é…ç½®æ¨¡å‹é¡ºåº**: å°†æ€§èƒ½æ›´å¥½ã€æ›´ç¨³å®šçš„æ¨¡å‹æ”¾åœ¨å‰é¢
3. **é€‚å½“è®¾ç½®é‡è¯•**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚é…ç½®æ¨¡å‹æ•°é‡å’Œå¯†é’¥æ•°é‡
4. **ç›‘æ§åˆ‡æ¢æ¬¡æ•°**: é€šè¿‡ `model_switch_count` ç›‘æ§æ¨¡å‹åˆ‡æ¢é¢‘ç‡

#### å…¨å±€æ¨¡å‹é…ç½®

æ”¯æŒé€šè¿‡CSVæ–‡ä»¶é…ç½®æ¨¡å‹çš„é«˜çº§å‚æ•°ï¼Œå®ç°æ›´ç²¾ç»†çš„æ¨¡å‹æ§åˆ¶ï¼š

**å…¨å±€é…ç½®æ–‡ä»¶æ ¼å¼** (`config/global_model_config.csv`):

æ–‡ä»¶æ ¼å¼ï¼šä»…æ”¯æŒ .csv å’Œ .xlsx æ ¼å¼ã€‚

> âš ï¸ **é‡è¦æç¤º**ï¼šè¡¨æ ¼æ–‡ä»¶ä¸­çš„å¸ƒå°”å€¼ï¼ˆTrue/Falseï¼‰å¿…é¡»æ˜¾å¼ç”¨è‹±æ–‡åŒå¼•å·åŒ…è£¹ï¼Œä¾‹å¦‚ `"True"` æˆ– `"""True"""`ã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿CSVè§£æå™¨æ­£ç¡®å¤„ç†å¸ƒå°”å€¼ï¼Œé¿å…ç±»å‹è½¬æ¢é—®é¢˜ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸ºäº†å’Œ0/1æ•°å€¼åŒºåˆ†ã€‚

| å‚æ•°å | è¯´æ˜ | é€‚ç”¨ platform/sdk |
| --- | --- | --- |
| `platform` | å¹³å°åç§° | - |
| `model_name` | æ¨¡å‹åç§° | - |
| `stream` | æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º | - |
| `stream_real` | æ˜¯å¦å¯ç”¨çœŸå®æµå¼è¾“å‡º | - |
| `response_format` | å“åº”æ ¼å¼ (`json` æˆ– `text`) | `zhipu` |
| `thinking` | æ€è€ƒæ¨¡å¼é…ç½® | `zhipu` |
| `extra_enable_thinking` | å¯ç”¨æ€è€ƒåŠŸèƒ½ï¼ˆä¼šåµŒå¥—åœ¨extra_bodyä¸­ï¼‰ | `modelscope`,`dashscope_openai` |
| `reasoning_effort` | æ¨ç†åŠªåŠ›ç¨‹åº¦ | `gemini` |

**é€šé…ç¬¦åŒ¹é…æ”¯æŒ**:
- `platform` - `model_name` æ ¼å¼
- ç²¾ç¡®åŒ¹é…: `dashscope,qwen3-max-preview`
- é€šé…ç¬¦åŒ¹é… (`*` åŒ…è£¹æ¨¡å‹åç§°):
  - ç¤ºä¾‹ï¼š`openai,*gpt*` (åŒ¹é…æ‰€æœ‰åŒ…å« gpt çš„æ¨¡å‹)
- é€šç”¨åŒ¹é… (`*` æ›¿ä»£æ¨¡å‹åç§°):
  - ç¤ºä¾‹ï¼š`zhipu,*` (åŒ¹é…æ™ºè°±å¹³å°æ‰€æœ‰æ¨¡å‹)

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from llmakits import load_models

# åŠ è½½å¸¦å…¨å±€é…ç½®çš„æ¨¡å‹
models, keys = load_models(
    'config/models_config.yaml',
    'config/keys_config.yaml',
    global_config='config/global_model_config.csv'
)
```

### 2. åŠ è½½æ¨¡å‹

```python
from llmakits import load_models

# æ–¹å¼1ï¼šä¼ å…¥é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰
models = load_models('config/models_config.yaml', 'config/keys_config.yaml')

# æ–¹å¼2ï¼šç›´æ¥ä¼ å…¥é…ç½®å­—å…¸
models_config = {
    "my_models": [
        {"model_name": "gpt-3.5-turbo", "sdk_name": "openai"}
    ]
}
model_keys = {
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "api_keys": ["your-api-key"]
    }
}
models = load_models(models_config, model_keys)

# æ–¹å¼3ï¼šä½¿ç”¨å…¨å±€é…ç½®ï¼ˆæ”¯æŒé«˜çº§å‚æ•°é…ç½®ï¼‰
models = load_models(
    'config/models_config.yaml',
    'config/keys_config.yaml',
    global_config='config/global_model_config.csv'  # å¯é€‰ï¼šå…¨å±€æ¨¡å‹é…ç½®
)

# è·å–æ¨¡å‹ç»„
my_models = models['my_models']
```

### 3. å‘é€æ¶ˆæ¯ï¼ˆå¤šæ¨¡å‹è°ƒåº¦ï¼‰

#### ä½¿ç”¨ ModelDispatcherï¼ˆæ¨èï¼‰

ModelDispatcher æä¾›äº†ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼Œæ¨èä½¿ç”¨ `execute_with_group` æ–¹æ³•ï¼š

**æ–¹å¼ä¸€ï¼šä½¿ç”¨æ¨¡å‹ç»„ï¼ˆæ¨èï¼‰**

```python
from llmakits import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹å¹¶åŠ è½½é…ç½®
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# ä½¿ç”¨æ¨¡å‹ç»„æ‰§è¡Œä»»åŠ¡ - è‡ªåŠ¨ç®¡ç†æ¨¡å‹çŠ¶æ€å’Œæ•…éšœè½¬ç§»
result, tokens = dispatcher.execute_with_group(message_info, group_name="generate_title")
print(f"ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")
print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {dispatcher.model_switch_count}")
```

#### æ¶ˆæ¯æ ¼å¼è¯´æ˜

`message_info` å‚æ•°æ”¯æŒä»¥ä¸‹å­—æ®µï¼š
- `system_prompt`: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
- `user_text`: ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
- `include_img`: æ˜¯å¦åŒ…å«å›¾ç‰‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤Falseï¼‰
- `img_list`: å›¾ç‰‡URLåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ï¼‰

åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
# ç®€å•æ–‡æœ¬å¯¹è¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# å¸¦å›¾ç‰‡çš„å¯¹è¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå›¾åƒåˆ†æä¸“å®¶",
    "user_text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡",
    "include_img": True,
    "img_list": ["https://example.com/image.jpg"]
}
# å¦‚æœinclude_img = True åŒæ—¶ img_list æ˜¯ç©ºçš„ï¼Œæ­¤æ—¶ä¼šæŠ¥å‡ºé”™è¯¯ã€‚
```

**æ–¹å¼äºŒï¼šæ‰‹åŠ¨ä¼ å…¥æ¨¡å‹åˆ—è¡¨**

```python
from llmakits import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
dispatcher = ModelDispatcher()

# å‡†å¤‡æ¶ˆæ¯å’Œæ¨¡å‹åˆ—è¡¨
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# æ‰§è¡Œä»»åŠ¡
result, tokens = dispatcher.execute_task(message_info, my_models)
```

#### é«˜çº§ç”¨æ³•ï¼šç»“æœéªŒè¯å’Œæ ¼å¼åŒ–

```python
from llmakits import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# å®šä¹‰ç»“æœéªŒè¯å‡½æ•°
def validate_result(result):
    """éªŒè¯ç»“æœæ˜¯å¦åŒ…å«å¿…è¦çš„å­—æ®µ"""
    return "python" in result.lower() and "ç¼–ç¨‹" in result

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶",
    "user_text": "è¯·ä»‹ç»Pythonè¯­è¨€çš„ç‰¹ç‚¹"
}

# æ‰§è¡Œä»»åŠ¡ï¼Œå¯ç”¨JSONæ ¼å¼åŒ–å’Œç»“æœéªŒè¯
result, tokens = dispatcher.execute_with_group(
    message_info,
    group_name="generate_title",
    format_json=True,           # æ ¼å¼åŒ–ä¸ºJSON
    validate_func=validate_result  # éªŒè¯ç»“æœ
)

print(f"éªŒè¯é€šè¿‡çš„ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")
```

#### é«˜çº§ç”¨æ³•ï¼šè·å–è¯¦ç»†æ‰§è¡Œç»“æœ

```python
from llmakits import ModelDispatcher
from llmakits.dispatcher import ExecutionResult

# åˆ›å»ºè°ƒåº¦å™¨
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶",
    "user_text": "è¯·ä»‹ç»Pythonè¯­è¨€çš„ç‰¹ç‚¹"
}

# è·å–è¯¦ç»†æ‰§è¡Œç»“æœ
result: ExecutionResult = dispatcher.execute_with_group(
    message_info,
    group_name="generate_title",
    return_detailed=True  # è¿”å›è¯¦ç»†ç»“æœ
)

print(f"è¿”å›æ¶ˆæ¯: {result.return_message}")
print(f"ä½¿ç”¨tokenæ•°: {result.total_tokens}")
print(f"æœ€åå°è¯•çš„æ¨¡å‹ç´¢å¼•: {result.last_tried_index}")
print(f"æ˜¯å¦æˆåŠŸ: {result.success}")
if result.error:
    print(f"é”™è¯¯ä¿¡æ¯: {result.error}")
```

#### é«˜çº§ç”¨æ³•ï¼šè€—æ—¶è­¦å‘Šç›‘æ§

```python
from llmakits import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨å¹¶è®¾ç½®è€—æ—¶è­¦å‘Šé˜ˆå€¼ï¼ˆå•ä½ï¼šç§’ï¼‰
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')
dispatcher.warning_time = 30  # è®¾ç½®30ç§’ä¸ºè€—æ—¶è­¦å‘Šé˜ˆå€¼

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "è¯·è¯¦ç»†ä»‹ç»Pythonç¼–ç¨‹è¯­è¨€åŠå…¶ç”Ÿæ€ç³»ç»Ÿ"
}

# æ‰§è¡Œä»»åŠ¡ - å½“æ¨¡å‹æ‰§è¡Œæ—¶é—´è¶…è¿‡30ç§’æ—¶ä¼šæ˜¾ç¤ºè­¦å‘Š
result, tokens = dispatcher.execute_with_group(message_info, group_name="generate_title")
print(f"ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")

# æŸ¥çœ‹æ¨¡å‹åˆ‡æ¢æ¬¡æ•°
print(f"æ¨¡å‹åˆ‡æ¢æ¬¡æ•°: {dispatcher.model_switch_count}")
```

#### é«˜çº§ç”¨æ³•ï¼šæŒ‡å®šèµ·å§‹æ¨¡å‹ç´¢å¼•

```python
from llmakits import ModelDispatcher

# åˆ›å»ºè°ƒåº¦å™¨
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "è¯·ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"
}

# ä»ç¬¬2ä¸ªæ¨¡å‹å¼€å§‹æ‰§è¡Œï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰
result, tokens = dispatcher.execute_with_group(
    message_info,
    group_name="generate_title",
    start_index=1  # ä»ç¬¬2ä¸ªæ¨¡å‹å¼€å§‹
)
print(f"ç»“æœ: {result}")
print(f"ä½¿ç”¨tokenæ•°: {tokens}")
```

**è€—æ—¶è­¦å‘ŠåŠŸèƒ½ç‰¹ç‚¹ï¼š**

1. **æ€§èƒ½ç›‘æ§**: å½“æ¨¡å‹æ‰§è¡Œæ—¶é—´è¶…è¿‡è®¾å®šé˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
2. **çµæ´»é…ç½®**: å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½®ä¸åŒçš„è­¦å‘Šé˜ˆå€¼
3. **ä¸å½±å“æ‰§è¡Œ**: è­¦å‘Šä¿¡æ¯ä¸ä¼šä¸­æ–­ä»»åŠ¡æ‰§è¡Œï¼Œä»…ä½œä¸ºæ€§èƒ½æç¤º
4. **è¯¦ç»†æŠ¥å‘Š**: è­¦å‘Šä¿¡æ¯åŒ…å«æ¨¡å‹åç§°å’Œå®é™…æ‰§è¡Œæ—¶é—´

**ä½¿ç”¨åœºæ™¯ï¼š**
- ç›‘æ§æ¨¡å‹å“åº”æ€§èƒ½ï¼ŒåŠæ—¶å‘ç°æ€§èƒ½é—®é¢˜
- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è·Ÿè¸ªå¼‚å¸¸è€—æ—¶çš„è¯·æ±‚
- ä¼˜åŒ–æ¨¡å‹é€‰æ‹©å’Œé…ç½®ï¼Œæé«˜æ•´ä½“å“åº”é€Ÿåº¦

#### å¢å¼ºç‰ˆè°ƒåº¦ç­–ç•¥ï¼šdispatcher_with_repair

```python
from llmakits import dispatcher_with_repair

# åˆ›å»ºè°ƒåº¦å™¨
from llmakits import ModelDispatcher
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# å‡†å¤‡æ¶ˆæ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªJSONæ•°æ®ç”Ÿæˆä¸“å®¶",
    "user_text": "è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å«äº§å“ä¿¡æ¯çš„JSONå¯¹è±¡"
}

# ä½¿ç”¨å¢å¼ºç‰ˆè°ƒåº¦ç­–ç•¥ - è‡ªåŠ¨ä¿®å¤JSONé”™è¯¯
try:
    result, tokens = dispatcher_with_repair(
        dispatcher=dispatcher,
        message_info=message_info,
        group_name="generate_json",  # ä¸»æ¨¡å‹ç»„åç§°
        validate_func=None,  # å¯é€‰ï¼šè‡ªå®šä¹‰éªŒè¯å‡½æ•°
        fix_json_config={
            "group_name": "fix_json",  # ä¿®å¤æ¨¡å‹ç»„åç§°
            "system_prompt": "ä½ æ˜¯ä¸€ä¸ªJSONä¿®å¤ä¸“å®¶ï¼Œè¯·ä¿®å¤ä¸‹é¢é”™è¯¯çš„JSONæ ¼å¼",
            "example_json": '{"name": "äº§å“åç§°", "price": 99.99}'  # å¯é€‰ï¼šJSONç¤ºä¾‹
        }
    )
    print(f"ä¿®å¤åçš„ç»“æœ: {result}")
    print(f"ä½¿ç”¨tokenæ•°: {tokens}")
except Exception as e:
    print(f"æ‰€æœ‰æ¨¡å‹å’Œä¿®å¤å°è¯•å‡å¤±è´¥: {e}")
```

**å¢å¼ºç‰ˆè°ƒåº¦ç­–ç•¥ç‰¹ç‚¹ï¼š**

1. **è‡ªåŠ¨ä¿®å¤JSONé”™è¯¯**ï¼šå½“ä¸»æ¨¡å‹è¿”å›æ ¼å¼é”™è¯¯çš„JSONæ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨ä¿®å¤æ¨¡å‹ç»„è¿›è¡Œä¿®å¤
2. **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ¯ä¸ªå¤±è´¥çš„æ¨¡å‹éƒ½ä¼šå°è¯•ä¿®å¤ï¼Œç¡®ä¿æ‰€æœ‰ä¸»æ¨¡å‹éƒ½æœ‰æœºä¼šå°è¯•
3. **ç‹¬ç«‹ä¿®å¤æµç¨‹**ï¼šä½¿ç”¨ç‹¬ç«‹çš„ä¿®å¤è°ƒåº¦å™¨ï¼Œé¿å…çŠ¶æ€æ··ä¹±
4. **è¯¦ç»†é”™è¯¯å¤„ç†**ï¼šåŒºåˆ†JSONé”™è¯¯å’Œå…¶ä»–ç±»å‹é”™è¯¯ï¼Œé‡‡å–ä¸åŒçš„å¤„ç†ç­–ç•¥

**ä½¿ç”¨åœºæ™¯ï¼š**
- éœ€è¦ç”Ÿæˆç»“æ„åŒ–JSONæ•°æ®çš„ä»»åŠ¡
- å¯¹JSONæ ¼å¼è¦æ±‚ä¸¥æ ¼çš„åœºæ™¯
- å¸Œæœ›æé«˜ä»»åŠ¡æˆåŠŸç‡çš„è‡ªåŠ¨åŒ–æµç¨‹

### 4. ç›´æ¥ä½¿ç”¨æ¨¡å‹å®¢æˆ·ç«¯

```python
from llmakits import BaseOpenai

# åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
model = BaseOpenai(
    platform="openai",
    base_url="https://api.openai.com/v1",
    api_keys=["your-api-key"],
    model_name="gpt-3.5-turbo"
)

# æ–¹æ³•1: ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨æ ¼å¼ï¼ˆå…¼å®¹OpenAIæ ¼å¼ï¼‰
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹"},
    {"role": "user", "content": "Hello!"}
]
result, tokens = model.send_message(messages)
print(f"å›å¤: {result}")

# æ–¹æ³•2: ä½¿ç”¨message_infoæ ¼å¼ï¼ˆæ¨èï¼‰
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ª helpful åŠ©æ‰‹",
    "user_text": "Hello!"
}
result, tokens = model.send_message([], message_info)
print(f"å›å¤: {result}")
```

#### é«˜çº§é…ç½®é€‰é¡¹

```python
from llmakits import BaseOpenai

# åˆ›å»ºå¸¦é«˜çº§é…ç½®çš„å®¢æˆ·ç«¯
client = BaseOpenai(
    platform="openai",
    base_url="https://api.openai.com/v1",
    api_keys=["your-api-key"],
    model_name="gpt-4o",
    stream=True,              # å¯ç”¨æµå¼è¾“å‡º
    stream_real=False,        # çœŸå®æµå¼è¾“å‡º
    request_timeout=60,       # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    max_retries=3            # æœ€å¤§é‡è¯•æ¬¡æ•°
)

# è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆDataFrameæ ¼å¼ï¼‰
models_df = client.models_df()
print(f"å¯ç”¨æ¨¡å‹: {models_df}")
```

#### è·å–æ¨¡å‹ä¿¡æ¯

```python
from llmakits import BaseOpenai

# åˆ›å»ºå®¢æˆ·ç«¯
client = BaseOpenai(
    platform="openai",
    base_url="https://api.openai.com/v1",
    api_keys=["your-api-key"],
    model_name="gpt-4o"
)

# è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆDataFrameæ ¼å¼ï¼ŒåŒ…å«åˆ›å»ºæ—¶é—´ç­‰ä¿¡æ¯ï¼‰
models_df = client.models_df()
print(f"æ¨¡å‹åˆ—è¡¨:")
print(models_df)

# è·å–ç‰¹å®šæ¨¡å‹çš„åˆ›å»ºæ—¶é—´
if 'created' in models_df.columns:
    gpt4o_created = models_df[models_df['id'] == 'gpt-4o']['created'].iloc[0]
    print(f"GPT-4o åˆ›å»ºæ—¶é—´: {gpt4o_created}")
```

#### é”™è¯¯å¤„ç†å’ŒAPIå¯†é’¥è€—å°½

```python
from llmakits import BaseOpenai

client = BaseOpenai(
    platform="openai",
    base_url="https://api.openai.com/v1",
    api_keys=["your-api-key"],
    model_name="gpt-4o"
)

try:
    response, tokens = client.send_message([], message_info)
    print(f"æ¨¡å‹å“åº”: {response}")
except Exception as e:
    if "API key exhausted" in str(e):
        print("APIå¯†é’¥å·²è€—å°½ï¼Œè¯·æ›´æ¢å¯†é’¥")
    else:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
```

## é«˜çº§åŠŸèƒ½

### æ¶ˆæ¯å¤„ç†

```python
from llmakits.message import prepare_messages, extract_field, convert_to_json

# å‡†å¤‡æ¶ˆæ¯
messages = prepare_messages(system="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹", user="è¯·å¸®å¿™", assistant="å¥½çš„")

# æå–å¹¶è½¬æ¢ä¸ºJSON
json_str = '{"name": "test"} some text'
result = convert_to_json(json_str)

# æå–å­—æ®µ
field_value = extract_field(json_str, "name")
print(field_value)  # è¾“å‡º: test

# æå–å¤šä¸ªå­—æ®µ
name, age = extract_field(json_str, "name", "age")
print(name)  # è¾“å‡º: test
print(age)  # è¾“å‡º: None

```

### ç”µå•†å·¥å…·

#### åŸºç¡€å·¥å…·å‡½æ•°

```python
from llmakits.e_commerce import contains_chinese, remove_chinese, shorten_title, validate_html

# ä½¿ç”¨ç®€å•å‡½æ•°
result = contains_chinese("æ™ºèƒ½æ‰‹æœº")  # è¿”å› True
title = shorten_title("ä¸€ä¸ªå¾ˆé•¿çš„å•†å“æ ‡é¢˜", 50)  # ç¼©å‡åˆ°50å­—ç¬¦

# HTMLéªŒè¯
allowed_tags = {'div', 'p', 'span', 'strong', 'em'}
is_valid, error_msg = validate_html("<div>å†…å®¹</div>", allowed_tags)
```

#### é«˜çº§ç”µå•†åŠŸèƒ½

ç”µå•†å·¥å…·å‡½æ•°ç°åœ¨æ”¯æŒä½¿ç”¨æ¨¡å‹ç»„åç§°ï¼Œæ›´åŠ ç®€æ´ï¼š

```python
from llmakits.e_commerce import generate_title, generate_html, fill_attr,predict_cat_direct, predict_cat_gradual, translate_options

# åˆ›å»ºè°ƒåº¦å™¨ - åŠ è½½é…ç½®
dispatcher = ModelDispatcher('config/models_config.yaml', 'config/keys_config.yaml')

# ç”Ÿæˆä¼˜åŒ–å•†å“æ ‡é¢˜
system_prompt = "ä½ æ˜¯ä¸€ä¸ªç”µå•†æ ‡é¢˜ä¼˜åŒ–ä¸“å®¶"
title = generate_title(
    dispatcher=dispatcher,
    title="åŸå§‹å•†å“æ ‡é¢˜",
    product_info="è¿™æ˜¯ä¸€ä¸ªéœ€è¦ä¼˜åŒ–çš„å•†å“ï¼ŒåŒ…å«è¯¦ç»†çš„äº§å“æè¿°å’Œç‰¹ç‚¹",
    system_prompt=system_prompt,
    group_name="generate_title",  # ä½¿ç”¨æ¨¡å‹ç»„åç§°
    min_length=10,
    max_length=225,
    min_word=2,      # æ ‡é¢˜æœ€å°‘åŒ…å«2ä¸ªå•è¯
    max_attempts=3   # æœ€å¤§é‡è¯•/ä¿®æ”¹æ¬¡æ•°
)

# é¢„æµ‹å•†å“ç±»ç›®
cat_tree = {}  # ç±»ç›®æ ‘æ•°æ®
categories = predict_cat_direct(
    dispatcher=dispatcher,
    product={"title": "å•†å“æ ‡é¢˜", "image_url": ""},  # å•†å“ä¿¡æ¯å­—å…¸
    cat_tree=cat_tree,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå•†å“åˆ†ç±»ä¸“å®¶ï¼Œè¯·æ ¹æ®å•†å“æ ‡é¢˜é¢„æµ‹åˆé€‚çš„å•†å“ç±»ç›®"
)

# é¢„æµ‹å•†å“ç±»ç›®ï¼ˆå¸¦JSONä¿®å¤åŠŸèƒ½ï¼‰
categories_with_fix = predict_cat_direct(
    dispatcher=dispatcher,
    product={"title": "æŠ¤å‘å–·é›¾", "image_url": "https://example.com/image.jpg"},
    cat_tree=cat_tree,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå•†å“åˆ†ç±»ä¸“å®¶ï¼Œè¯·æ ¹æ®å•†å“æ ‡é¢˜å’Œå›¾ç‰‡é¢„æµ‹åˆé€‚çš„å•†å“ç±»ç›®",
    fix_json_config={
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªJSONæ ¼å¼ä¿®å¤ä¸“å®¶ï¼Œè¯·ä¿®å¤ä¸‹é¢é”™è¯¯çš„JSONæ ¼å¼",
        "group_name": "fix_json"
    }
)

# æ¢¯åº¦é¢„æµ‹å•†å“ç±»ç›®ï¼ˆé€çº§é¢„æµ‹ï¼‰
categories_gradual = predict_cat_gradual(
    dispatcher=dispatcher,
    product={"title": "æ™ºèƒ½æ‰‹æœº", "image_url": "https://example.com/image.jpg"},
    cat_tree=cat_tree,
    predict_config={
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå•†å“åˆ†ç±»ä¸“å®¶ï¼Œè¯·æ ¹æ®å•†å“æ ‡é¢˜å’Œå›¾ç‰‡é€çº§é¢„æµ‹åˆé€‚çš„å•†å“ç±»ç›®",
        "group_name": "predict_category"
    },
    fix_json_config={
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªJSONæ ¼å¼ä¿®å¤ä¸“å®¶ï¼Œè¯·ä¿®å¤ä¸‹é¢é”™è¯¯çš„JSONæ ¼å¼",
        "group_name": "fix_json"
    }
)

# ç¿»è¯‘å•†å“é€‰é¡¹
options = ["çº¢è‰²", "è“è‰²", "ç»¿è‰²"]
translated = translate_options(
    dispatcher=dispatcher,
    title="å•†å“æ ‡é¢˜",
    options=options,
    to_lang="english",
    group_name="translate_box",  # ä½¿ç”¨æ¨¡å‹ç»„åç§°
    system_prompt="ç¿»è¯‘å•†å“é€‰é¡¹"
)


# ç”ŸæˆHTMLå•†å“æè¿°ï¼ˆè‡ªåŠ¨ä¿®å¤é”™è¯¯ï¼‰
product_info = """
äº§å“åç§°ï¼šæ™ºèƒ½æ‰‹è¡¨
ç‰¹ç‚¹ï¼šé˜²æ°´ã€å¿ƒç‡ç›‘æµ‹ã€GPSå®šä½
æè´¨ï¼šä¸é”ˆé’¢è¡¨å¸¦ï¼Œå¼ºåŒ–ç»ç’ƒè¡¨é¢
é€‚ç”¨åœºæ™¯ï¼šè¿åŠ¨ã€æ—¥å¸¸ä½©æˆ´
"""

html_description = generate_html(
    dispatcher=dispatcher,
    product_info=product_info,
    generate_prompt="ä½ æ˜¯ä¸€ä¸ªç”µå•†äº§å“æè¿°ä¸“å®¶ï¼Œè¯·æ ¹æ®äº§å“ä¿¡æ¯ç”Ÿæˆç¾è§‚çš„HTMLæ ¼å¼æè¿°ï¼ŒåŒ…å«æ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ç­‰ç»“æ„",
    fix_prompt="ä¿®å¤HTMLä¸­çš„ä¸å…è®¸æ ‡ç­¾ï¼Œç¡®ä¿HTMLæ ¼å¼æ­£ç¡®",
    generate_group="generate_html",  # ç”ŸæˆHTMLä½¿ç”¨çš„æ¨¡å‹ç»„
    fix_group="fix_html",       # ä¿®å¤HTMLä½¿ç”¨çš„æ¨¡å‹ç»„
    allowed_tags={'div', 'p', 'h1', 'h2', 'h3', 'ul', 'li', 'strong', 'em', 'span', 'br'}
)

# å¡«å……å±æ€§å€¼

# å‡†å¤‡æ¶ˆæ¯ä¿¡æ¯
message_info = {
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå•†å“å±æ€§å¡«å……ä¸“å®¶ï¼Œè¯·æ ¹æ®å•†å“ä¿¡æ¯å¡«å……ç›¸åº”çš„å±æ€§å€¼",
    "user_text": "è¯·ä¸ºæ™ºèƒ½æ‰‹è¡¨å¡«å……é¢œè‰²å±æ€§"
}

# å®šä¹‰å¯é€‰é¡¹åˆ—è¡¨
color_choices = ["é»‘è‰²", "ç™½è‰²", "è“è‰²", "çº¢è‰²", "ç²‰è‰²", "é‡‘è‰²", "é“¶è‰²"]

# ä½¿ç”¨fill_attrå‡½æ•°å¡«å……å±æ€§
filled_result = fill_attr(
    dispatcher=dispatcher,
    message_info=message_info,
    group="generate_title",  # ä½¿ç”¨æ¨¡å‹ç»„åç§°
    choices=color_choices    # å¯é€‰å€¼åˆ—è¡¨ï¼Œç”¨äºéªŒè¯ç»“æœ
)

print(f"å¡«å……çš„å±æ€§ç»“æœ: {filled_result}")
```

## è®¸å¯è¯

Apache 2.0 License
